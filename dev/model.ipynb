{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baae592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class BlinkSeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    eye_seq : (seq_len, 1, 24, 12)  float32  [0‑1]  (pinned)\n",
    "    num_seq : (seq_len, 7)          float32  (z‑scored, pinned)\n",
    "    label   : int64 0/1\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path, seq_len=30, train=True,\n",
    "                 split_ratio=0.8, numeric_stats=None):\n",
    "        df = pd.read_csv(csv_path).dropna().reset_index(drop=True)\n",
    "\n",
    "        # ---- contiguous train/test split -----------------------------------\n",
    "        split = int(len(df) * split_ratio)\n",
    "        df = df.iloc[:split] if train else df.iloc[split:]\n",
    "\n",
    "        px_cols  = [c for c in df.columns if c.startswith('px_')]\n",
    "        num_cols = ['ratio_left','ratio_right','ratio_avg',\n",
    "                    'v_left','v_right','h_left','h_right']\n",
    "\n",
    "        # ---- numeric features : z‑score ------------------------------------\n",
    "        X_num = df[num_cols].values.astype(np.float32)\n",
    "        if numeric_stats is None:\n",
    "            mean, std = X_num.mean(0), X_num.std(0) + 1e-6\n",
    "        else:\n",
    "            mean, std = numeric_stats\n",
    "        X_num = (X_num - mean) / std\n",
    "\n",
    "        # ---- pixel patch : scale 0‑1 ---------------------------------------\n",
    "        X_px = (df[px_cols].values.astype(np.float32) / 255.0) \\\n",
    "               .reshape(-1, 1, 24, 12)\n",
    "\n",
    "        # ---- convert ONCE to pinned tensors --------------------------------\n",
    "        self.X_num = torch.from_numpy(X_num)   # stay regular CPU tensors\n",
    "        self.X_px  = torch.from_numpy(X_px )\n",
    "        self.labels = torch.from_numpy(df['manual_blink'].values.astype(np.int64))\n",
    "        self.seq_len = seq_len\n",
    "        self.numeric_stats = (mean, std)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels) - self.seq_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sl = slice(idx, idx + self.seq_len)\n",
    "        # NO conversion inside __getitem__\n",
    "        return (self.X_px [sl],           # (seq,1,24,12)\n",
    "                self.X_num[sl],           # (seq,7)\n",
    "                self.labels[idx+self.seq_len-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36f947f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=256,\n",
    "                      shuffle=True,  num_workers=0, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=256,\n",
    "                      shuffle=False, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1936d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BlinkDetector(nn.Module):\n",
    "    def __init__(self, num_features=7, img_height=24, img_width=12, \n",
    "                 conv_channels=(16, 32), lstm_hidden=64, lstm_layers=1, bidirectional=True):\n",
    "        super(BlinkDetector, self).__init__()\n",
    "        # CNN feature extractor for eye patch\n",
    "        self.conv1 = nn.Conv2d(1, conv_channels[0], kernel_size=3, padding=1)  # conv layer 1\n",
    "        self.conv2 = nn.Conv2d(conv_channels[0], conv_channels[1], kernel_size=3, padding=1)  # conv layer 2\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)  # 2x2 pooling reduces HxW by factor of 2\n",
    "\n",
    "        # Compute flattened size after two conv+pool layers\n",
    "        conv_out_h = img_height // 4   # 24 -> 6 after two pools\n",
    "        conv_out_w = img_width  // 4   # 12 -> 3 after two pools\n",
    "        conv_flat_dim = conv_out_h * conv_out_w * conv_channels[1]\n",
    "        # Fully-connected layer to embed CNN output to a fixed size (e.g. 64)\n",
    "        self.img_fc = nn.Linear(conv_flat_dim, 64)\n",
    "\n",
    "        # Fully-connected layer to embed numeric features to a similar size (e.g. 16)\n",
    "        self.num_fc = nn.Linear(num_features, 16)\n",
    "\n",
    "        # LSTM for sequence modeling (input size = 64+16, hidden size = lstm_hidden)\n",
    "        lstm_input_dim = 64 + 16\n",
    "        self.lstm = nn.LSTM(lstm_input_dim, lstm_hidden, num_layers=lstm_layers, \n",
    "                             batch_first=True, bidirectional=bidirectional)\n",
    "        # Final classifier layer\n",
    "        self.bidirectional = bidirectional\n",
    "        output_dim = lstm_hidden * (2 if bidirectional else 1)\n",
    "        self.fc = nn.Linear(output_dim, 1)  # single output logit\n",
    "\n",
    "    def forward(self, eye_patches, features):\n",
    "        \"\"\"\n",
    "        eye_patches: Tensor of shape (batch, seq_len, 1, 24, 12)\n",
    "        features:    Tensor of shape (batch, seq_len, num_features)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _, H, W = eye_patches.shape\n",
    "\n",
    "        # CNN forward pass for all patches in the sequence\n",
    "        x = eye_patches.view(batch_size * seq_len, 1, H, W)      # merge batch and sequence for CNN\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)                                        # shape: [batch*seq, conv_channels[1], H/4, W/4]\n",
    "        x = x.view(x.size(0), -1)                               # flatten spatial dims\n",
    "        x = self.relu(self.img_fc(x))                           # image patch embedded to 64-dim\n",
    "\n",
    "        # Numeric feature embedding\n",
    "        f = features.view(batch_size * seq_len, -1)             # flatten batch and seq\n",
    "        f = self.relu(self.num_fc(f))                           # embed numeric features to 16-dim\n",
    "\n",
    "        # Combine image and numeric features\n",
    "        combined = torch.cat([x, f], dim=1)                     # shape: [batch*seq, 64+16]\n",
    "        combined = combined.view(batch_size, seq_len, -1)       # reshape to [batch, seq_len, feature_dim]\n",
    "\n",
    "        # LSTM over time\n",
    "        lstm_out, (h_n, c_n) = self.lstm(combined)              # h_n shape: (num_layers*direction, batch, hidden)\n",
    "        if self.bidirectional:\n",
    "            # Concatenate final forward and backward hidden states\n",
    "            # For 1-layer LSTM: h_n[0] = last hidden (forward), h_n[1] = last hidden (backward)\n",
    "            forward_h = h_n[-2]    # shape [batch, hidden]\n",
    "            backward_h = h_n[-1]   # shape [batch, hidden]\n",
    "            seq_repr = torch.cat([forward_h, backward_h], dim=1)  # shape [batch, 2*hidden]\n",
    "        else:\n",
    "            seq_repr = h_n[-1]    # shape [batch, hidden]\n",
    "\n",
    "        # Final output layer\n",
    "        logit = self.fc(seq_repr)   # shape [batch, 1]\n",
    "        return logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ca5f55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BlinkSeqDataset' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m model = BlinkDetector(num_features=\u001b[32m7\u001b[39m).to(device)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ---- imbalance weighting ---------------------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m blink_frac = \u001b[43mtrain_ds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabels\u001b[49m.float().mean().item()\n\u001b[32m     13\u001b[39m pos_weight = torch.tensor([(\u001b[32m1\u001b[39m-blink_frac)/blink_frac], device=device)\n\u001b[32m     14\u001b[39m criterion  = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
      "\u001b[31mAttributeError\u001b[39m: 'BlinkSeqDataset' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch, torch.cuda.amp as amp\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # optimise convs\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"device:\", device)\n",
    "\n",
    "model = BlinkDetector(num_features=7).to(device)\n",
    "\n",
    "# ---- imbalance weighting ---------------------------------------------\n",
    "blink_frac = train_ds.labels.float().mean().item()\n",
    "pos_weight = torch.tensor([(1-blink_frac)/blink_frac], device=device)\n",
    "criterion  = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer  = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler  = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, factor=0.5, patience=3)\n",
    "\n",
    "scaler = amp.GradScaler('cuda')           # mixed precision\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum, all_pred, all_true = 0.0, [], []\n",
    "\n",
    "    for eye, num, lbl in loader:\n",
    "        eye = eye.to(device, non_blocking=True).float()\n",
    "        num = num.to(device, non_blocking=True).float()\n",
    "        lbl = lbl.to(device, non_blocking=True).float()\n",
    "\n",
    "        with amp.autocast():\n",
    "            logits = model(eye, num).squeeze(1)\n",
    "            loss   = criterion(logits, lbl)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        loss_sum += loss.item() * lbl.size(0)\n",
    "        all_pred.append(torch.sigmoid(logits).detach().cpu() > 0.5)\n",
    "        all_true.append(lbl.cpu().bool())\n",
    "\n",
    "    y_pred = torch.cat(all_pred)\n",
    "    y_true = torch.cat(all_true)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "                           y_true, y_pred, average='binary', zero_division=0)\n",
    "    return loss_sum / len(loader.dataset), acc, prec, rec, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba84234",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 12828, 33428) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmpty\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1283\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\queue.py:179\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    180\u001b[39m \u001b[38;5;28mself\u001b[39m.not_empty.wait(remaining)\n",
      "\u001b[31mEmpty\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m best_f1, patience, epochs_no_improve = \u001b[32m0\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m40\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     tr_loss, _, _, _, tr_f1 = \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     va_loss, _, _, _, va_f1 = run_epoch(test_dl,  train=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m     scheduler.step(va_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mrun_epoch\u001b[39m\u001b[34m(loader, train)\u001b[39m\n\u001b[32m     23\u001b[39m model.train() \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m model.eval()\n\u001b[32m     24\u001b[39m loss_sum, all_pred, all_true = \u001b[32m0.0\u001b[39m, [], []\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43meye\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43meye\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43meye\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1443\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1444\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1445\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1297\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1296\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1298\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1299\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 12828, 33428) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "best_f1, patience, epochs_no_improve = 0, 7, 0\n",
    "for epoch in range(40):\n",
    "    tr_loss, _, _, _, tr_f1 = run_epoch(train_dl, train=True)\n",
    "    va_loss, _, _, _, va_f1 = run_epoch(test_dl,  train=False)\n",
    "    scheduler.step(va_loss)\n",
    "\n",
    "    print(f\"[{epoch+1:02}] trainL {tr_loss:.3f} F1 {tr_f1:.3f} | \"\n",
    "          f\"valL {va_loss:.3f} F1 {va_f1:.3f}\")\n",
    "\n",
    "    if va_f1 > best_f1 + 1e-3:\n",
    "        best_f1, epochs_no_improve = va_f1, 0\n",
    "        torch.save(model.state_dict(), \"blink_best.pth\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stop – no F1 improvement\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba79519",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"blink_best.pth\"))\n",
    "model.eval()\n",
    "\n",
    "def predict_sequence(eye_seq, num_seq):\n",
    "    # eye_seq: (30,1,24,12) numpy\n",
    "    eye = torch.from_numpy(eye_seq).unsqueeze(0).float().to(device)\n",
    "    num = torch.from_numpy(num_seq).unsqueeze(0).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        prob = torch.sigmoid(model(eye, num)).item()\n",
    "    return prob   # >0.5 → intentional blink\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
